# Test Technique â€“ Lead Infrastructure & DevOps

## ğŸ¯ Objectif
Ã‰valuer les compÃ©tences d'un Lead Infrastructure & DevOps pour concevoir, dÃ©ployer et maintenir une infrastructure robuste, sÃ©curisÃ©e et scalable pour un environnement multi-campus (Cotonou, Abidjan).

---

## ğŸ–¥ï¸ Environnement de test fourni
- **PC Windows** avec :
  - Docker Desktop (avec WSL2)
  - Terraform
  - Git
  - VS Code (ou Ã©diteur de votre choix)
  - Connexion Internet

---

## ğŸ“‹ Structure des exercices

### **Partie 1 : Infrastructure as Code (IaC)** â€” 35%
### **Partie 2 : Orchestration & Conteneurisation** â€” 30%
### **Partie 3 : Architecture Multi-Campus** â€” 20%
### **Partie 4 : Monitoring & SÃ©curitÃ©** â€” 15%

---

## ğŸ—ï¸ PARTIE 1 â€” Infrastructure as Code (Terraform)

### Exercice 1.1 â€” Provisionnement Cloud SimulÃ© (Local)
**Contexte :** Vous devez crÃ©er une infrastructure reproductible pour hÃ©berger les plateformes AEIG (LMS, CRM, Intranet).

**TÃ¢ches :**
1. CrÃ©er une infrastructure Terraform qui provisionne **localement** (via Docker provider) :
   - 3 conteneurs applicatifs (web-cotonou, web-abidjan, web-backup)
   - 1 conteneur base de donnÃ©es PostgreSQL
   - 1 conteneur reverse proxy Nginx
   - 1 rÃ©seau privÃ© isolÃ©

2. Utiliser des **modules Terraform** pour :
   - Module `network` : crÃ©ation du rÃ©seau Docker
   - Module `database` : dÃ©ploiement PostgreSQL avec volumes persistants
   - Module `application` : dÃ©ploiement des apps avec variables d'environnement

3. ImplÃ©menter des **workspaces Terraform** :
   - `dev` : 1 instance de chaque service
   - `staging` : 2 instances applicatives (load balancing)
   - `production` : 3 instances + rÃ©plication DB

**Livrables :**
```
terraform/
â”œâ”€â”€ main.tf
â”œâ”€â”€ variables.tf
â”œâ”€â”€ outputs.tf
â”œâ”€â”€ terraform.tfvars.example
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ network/
â”‚   â”œâ”€â”€ database/
â”‚   â””â”€â”€ application/
â””â”€â”€ environments/
    â”œâ”€â”€ dev.tfvars
    â”œâ”€â”€ staging.tfvars
    â””â”€â”€ production.tfvars
```

**CritÃ¨res d'Ã©valuation :**
- âœ… Code modulaire et rÃ©utilisable
- âœ… Variables paramÃ©trables (pas de valeurs en dur)
- âœ… State management (local backend documentÃ©)
- âœ… Documentation des commandes (README)

---

### Exercice 1.2 â€” Infrastructure Cloud AWS (Conception)
**Contexte :** AEIG souhaite migrer vers AWS pour bÃ©nÃ©ficier de la scalabilitÃ© cloud.

**TÃ¢ches :**
1. CrÃ©er un **diagramme d'architecture** (draw.io, Lucidchart, ou ASCII art) montrant :
   - VPC multi-AZ (2 zones de disponibilitÃ©)
   - Subnets publics/privÃ©s
   - EC2 instances derriÃ¨re ALB (Application Load Balancer)
   - RDS PostgreSQL Multi-AZ
   - S3 pour stockage statique
   - CloudWatch pour monitoring
   - VPN Site-to-Site vers campus Cotonou

2. Ã‰crire le code Terraform pour **VPC + Subnets uniquement** (pas besoin de dÃ©ployer rÃ©ellement) :
   - VPC avec CIDR 10.0.0.0/16
   - 2 subnets publics (10.0.1.0/24, 10.0.2.0/24)
   - 2 subnets privÃ©s (10.0.10.0/24, 10.0.11.0/24)
   - Internet Gateway
   - NAT Gateway
   - Route tables

**Livrables :**
```
terraform/aws/
â”œâ”€â”€ architecture-diagram.png (ou .drawio)
â”œâ”€â”€ vpc.tf
â”œâ”€â”€ subnets.tf
â”œâ”€â”€ routing.tf
â”œâ”€â”€ variables.tf
â””â”€â”€ README.md (explication des choix)
```

**CritÃ¨res d'Ã©valuation :**
- âœ… Architecture haute disponibilitÃ©
- âœ… Segmentation rÃ©seau sÃ©curisÃ©e
- âœ… Justification des choix techniques
- âœ… Estimation des coÃ»ts (dans README)

---

## ğŸ³ PARTIE 2 â€” Orchestration Kubernetes

### Exercice 2.1 â€” DÃ©ploiement Kubernetes Local
**Contexte :** Vous devez conteneuriser et orchestrer les applications AEIG avec Kubernetes.

**TÃ¢ches :**
1. Activer Kubernetes dans Docker Desktop
2. CrÃ©er les manifestes Kubernetes pour dÃ©ployer :
   - **Deployment** : Application Node.js (3 replicas)
   - **Service** : ClusterIP pour l'app
   - **Ingress** : Exposition via nginx-ingress
   - **ConfigMap** : Variables d'environnement
   - **Secret** : Credentials DB (base64)
   - **PersistentVolumeClaim** : Stockage pour uploads

3. ImplÃ©menter :
   - **Liveness probe** : `/health` endpoint
   - **Readiness probe** : `/ready` endpoint
   - **Resource limits** : CPU 500m, Memory 512Mi
   - **HorizontalPodAutoscaler** : Scale 2-5 replicas si CPU > 70%

**Livrables :**
```
kubernetes/
â”œâ”€â”€ namespace.yaml
â”œâ”€â”€ deployment.yaml
â”œâ”€â”€ service.yaml
â”œâ”€â”€ ingress.yaml
â”œâ”€â”€ configmap.yaml
â”œâ”€â”€ secret.yaml
â”œâ”€â”€ pvc.yaml
â”œâ”€â”€ hpa.yaml
â””â”€â”€ README.md (commandes kubectl)
```

**CritÃ¨res d'Ã©valuation :**
- âœ… Manifestes valides et fonctionnels
- âœ… Bonnes pratiques K8s (labels, selectors)
- âœ… Autoscaling configurÃ©
- âœ… Documentation des tests

---

### Exercice 2.2 â€” Helm Chart
**Contexte :** Faciliter le dÃ©ploiement multi-environnements avec Helm.

**TÃ¢ches :**
1. CrÃ©er un Helm Chart pour l'application :
   - Templates pour tous les manifestes K8s
   - Values.yaml avec paramÃ¨tres par environnement
   - Helpers pour labels communs

2. CrÃ©er 3 fichiers values :
   - `values-dev.yaml` : 1 replica, resources minimales
   - `values-staging.yaml` : 2 replicas
   - `values-prod.yaml` : 3 replicas, resources Ã©levÃ©es

**Livrables :**
```
helm/
â”œâ”€â”€ Chart.yaml
â”œâ”€â”€ values.yaml
â”œâ”€â”€ values-dev.yaml
â”œâ”€â”€ values-staging.yaml
â”œâ”€â”€ values-prod.yaml
â””â”€â”€ templates/
    â”œâ”€â”€ deployment.yaml
    â”œâ”€â”€ service.yaml
    â”œâ”€â”€ ingress.yaml
    â””â”€â”€ _helpers.tpl
```

**CritÃ¨res d'Ã©valuation :**
- âœ… Chart installable avec `helm install`
- âœ… ParamÃ©trage flexible
- âœ… Documentation Helm

---

## ğŸŒ PARTIE 3 â€” Architecture Multi-Campus

### Exercice 3.1 â€” StratÃ©gie de RÃ©plication
**Contexte :** AEIG a 2 campus (Cotonou, Abidjan) qui doivent partager certaines donnÃ©es.

**TÃ¢ches :**
1. Concevoir une architecture de rÃ©plication de base de donnÃ©es :
   - SchÃ©ma Master-Slave ou Master-Master
   - Diagramme de flux de donnÃ©es
   - StratÃ©gie de rÃ©solution de conflits

2. ImplÃ©menter avec Docker Compose :
   - 2 conteneurs PostgreSQL (cotonou-db, abidjan-db)
   - Configuration de rÃ©plication streaming
   - Script de test de failover

**Livrables :**
```
multi-campus/
â”œâ”€â”€ architecture-replication.md
â”œâ”€â”€ docker-compose-replication.yml
â”œâ”€â”€ postgres-master/
â”‚   â””â”€â”€ postgresql.conf
â”œâ”€â”€ postgres-slave/
â”‚   â””â”€â”€ postgresql.conf
â””â”€â”€ scripts/
    â”œâ”€â”€ setup-replication.sh
    â””â”€â”€ test-failover.sh
```

**CritÃ¨res d'Ã©valuation :**
- âœ… RÃ©plication fonctionnelle
- âœ… Plan de disaster recovery
- âœ… Documentation des procÃ©dures

---

## ğŸ“Š PARTIE 4 â€” Monitoring, Logging & SÃ©curitÃ©

### Exercice 4.1 â€” Stack d'ObservabilitÃ© ComplÃ¨te
**Contexte :** Mettre en place une solution de monitoring production-grade.

**TÃ¢ches :**
1. DÃ©ployer avec Docker Compose :
   - **Prometheus** : Collecte de mÃ©triques
   - **Grafana** : Dashboards
   - **Alertmanager** : Alertes (email/webhook simulÃ©)
   - **Loki** : Logs centralisÃ©s
   - **Promtail** : Collecteur de logs
   - **Node Exporter** : MÃ©triques systÃ¨me

2. Configurer :
   - Dashboard Grafana avec :
     - CPU/Memory/Disk usage
     - RequÃªtes HTTP (latency, error rate)
     - Database connections
     - Uptime SLA
   - RÃ¨gles d'alerte Prometheus :
     - CPU > 80% pendant 5min
     - Error rate > 5%
     - Disk usage > 85%
     - Service down

3. CrÃ©er un **runbook** (playbook de rÃ©action) :
   - ProcÃ©dure si alerte "High CPU"
   - ProcÃ©dure si alerte "Service Down"
   - ProcÃ©dure si alerte "Database Slow"

**Livrables :**
```
monitoring/
â”œâ”€â”€ docker-compose-monitoring.yml
â”œâ”€â”€ prometheus/
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ alerts.yml
â”œâ”€â”€ grafana/
â”‚   â””â”€â”€ dashboards/
â”‚       â””â”€â”€ infrastructure-dashboard.json
â”œâ”€â”€ alertmanager/
â”‚   â””â”€â”€ alertmanager.yml
â”œâ”€â”€ loki/
â”‚   â””â”€â”€ loki-config.yml
â””â”€â”€ runbooks/
    â”œâ”€â”€ high-cpu.md
    â”œâ”€â”€ service-down.md
    â””â”€â”€ database-slow.md
```

**CritÃ¨res d'Ã©valuation :**
- âœ… Stack complÃ¨te fonctionnelle
- âœ… Dashboard pertinent
- âœ… Alertes configurÃ©es
- âœ… Runbooks dÃ©taillÃ©s

---

### Exercice 4.2 â€” SÃ©curitÃ© & Hardening
**Contexte :** SÃ©curiser l'infrastructure et les conteneurs.

**TÃ¢ches :**
1. Scanner les vulnÃ©rabilitÃ©s :
   - Utiliser **Trivy** pour scanner les images Docker
   - GÃ©nÃ©rer un rapport de vulnÃ©rabilitÃ©s
   - Proposer des correctifs

2. Hardening des conteneurs :
   - Images multi-stage (rÃ©duire la surface d'attaque)
   - User non-root dans Dockerfile
   - Read-only filesystem oÃ¹ possible
   - Secrets via Docker secrets (pas d'env vars)

3. CrÃ©er un document de **politique de sÃ©curitÃ©** :
   - Gestion des secrets (Vault, AWS Secrets Manager)
   - Rotation des credentials
   - Backup & encryption
   - ProcÃ©dure en cas de breach

**Livrables :**
```
security/
â”œâ”€â”€ trivy-scan-report.txt
â”œâ”€â”€ Dockerfile.hardened
â”œâ”€â”€ docker-compose-secrets.yml
â””â”€â”€ security-policy.md
```

**CritÃ¨res d'Ã©valuation :**
- âœ… Scan de vulnÃ©rabilitÃ©s effectuÃ©
- âœ… Dockerfile sÃ©curisÃ©
- âœ… Politique de sÃ©curitÃ© complÃ¨te



## ğŸ“¦ Livrables Finaux

```
technical-test-lead-infra/
â”œâ”€â”€ terraform/
â”‚   â”œâ”€â”€ local/          (Exercice 1.1)
â”‚   â””â”€â”€ aws/            (Exercice 1.2)
â”œâ”€â”€ kubernetes/         (Exercice 2.1)
â”œâ”€â”€ helm/               (Exercice 2.2)
â”œâ”€â”€ multi-campus/       (Exercice 3.1)
â”œâ”€â”€ network/            (Exercice 3.2)
â”œâ”€â”€ monitoring/         (Exercice 4.1)
â”œâ”€â”€ security/           (Exercice 4.2)
â””â”€â”€ README.md           (Instructions globales)
```

---



## ğŸ“Š BarÃ¨me d'Ã‰valuation

| CritÃ¨re | Points | DÃ©tails |
|---------|--------|---------|
| **IaC (Terraform)** | 35% | ModularitÃ©, bonnes pratiques, documentation |
| **Orchestration (K8s/Helm)** | 30% | Manifestes valides, scalabilitÃ©, autoscaling |
| **Architecture Multi-Campus** | 20% | RÃ©plication, rÃ©seau, rÃ©silience |
| **Monitoring & SÃ©curitÃ©** | 15% | ObservabilitÃ©, alertes, hardening |

---

## ğŸš€ Soumission

1. **Fork** le repository GitHub
2. CrÃ©er une branche `lead-infra/<votre-nom>`
3. Commits rÃ©guliers avec messages clairs
4. **Pull Request** avec titre : `[Lead Infra] PrÃ©nom NOM`
5. Dans la PR, inclure :
   - RÃ©sumÃ© des choix techniques
   - Temps passÃ© par partie
   - DifficultÃ©s rencontrÃ©es
   - AmÃ©liorations futures

---

## ğŸ“ Support Technique

En cas de blocage technique (installation, configuration) :
- Documenter le problÃ¨me dans `ISSUES.md`
- Proposer une solution alternative
- Continuer sur les autres exercices

**Note :** La capacitÃ© Ã  dÃ©bloquer des situations techniques fait partie de l'Ã©valuation.

---

## âœ… Checklist Avant Soumission

- [ ] Tous les fichiers sont versionnÃ©s (Git)
- [ ] Pas de secrets/credentials commitÃ©es
- [ ] README.md avec instructions claires
- [ ] Code testÃ© et fonctionnel
- [ ] Documentation complÃ¨te
- [ ] answers-lead.md rempli
- [ ] Pull Request crÃ©Ã©e

---

**Bonne chance ! ğŸš€**

*Ce test Ã©value votre capacitÃ© Ã  concevoir, dÃ©ployer et maintenir une infrastructure robuste pour un environnement Ã©ducatif multi-campus. Nous recherchons un profil sÃ©nior capable de prendre des dÃ©cisions architecturales stratÃ©giques.*
